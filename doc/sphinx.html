<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>Sphinx 0.9.7 reference manual</title><style type="text/css">
pre.programlisting
{
	background-color:	#f0f0f0;
	padding:			0.5em;
	margin-left:		2em;
	margin-right:		2em;
}
</style><meta name="generator" content="DocBook XSL Stylesheets V1.70.1"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="article" lang="en"><div class="titlepage"><div><div><h1 class="title"><a name="id94321"></a>Sphinx 0.9.7 reference manual</h1></div><div><h3 class="subtitle"><i>Free open-source SQL full-text search engine</i></h3></div><div><p class="copyright">Copyright &copy; 2001-2007 Andrew Aksyonoff, <code class="email">&lt;<a href="mailto:shodan(at)shodan.ru">shodan(at)shodan.ru</a>&gt;</code></p></div></div><hr></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#intro">1. Introduction</a></span></dt><dd><dl><dt><span class="sect2"><a href="#about">1.1. About</a></span></dt><dt><span class="sect2"><a href="#features">1.2. Sphinx features</a></span></dt><dt><span class="sect2"><a href="#getting">1.3. Where to get Sphinx</a></span></dt><dt><span class="sect2"><a href="#license">1.4. License</a></span></dt><dt><span class="sect2"><a href="#author">1.5. Author and contributors</a></span></dt><dt><span class="sect2"><a href="#history">1.6. History</a></span></dt></dl></dd><dt><span class="sect1"><a href="#installation">2. Installation</a></span></dt><dd><dl><dt><span class="sect2"><a href="#supported-system">2.1. Supported systems</a></span></dt><dt><span class="sect2"><a href="#required-tools">2.2. Required tools</a></span></dt><dt><span class="sect2"><a href="#installing">2.3. Installing Sphinx</a></span></dt><dt><span class="sect2"><a href="#install-problems">2.4. Known installation issues</a></span></dt><dt><span class="sect2"><a href="#quick-tour">2.5. Quick Sphinx usage tour</a></span></dt></dl></dd><dt><span class="sect1"><a href="#indexing">3. Indexing</a></span></dt><dd><dl><dt><span class="sect2"><a href="#sources">3.1. Data sources</a></span></dt><dt><span class="sect2"><a href="#attributes">3.2. Attributes</a></span></dt><dt><span class="sect2"><a href="#indexes">3.3. Indexes</a></span></dt><dt><span class="sect2"><a href="#data-restrictions">3.4. Restrictions on the source data</a></span></dt><dt><span class="sect2"><a href="#charsets">3.5. Charsets, case folding, and translation tables</a></span></dt><dt><span class="sect2"><a href="#sql">3.6. SQL data sources (MySQL, PostgreSQL)</a></span></dt><dt><span class="sect2"><a href="#xmlpipe">3.7. XMLpipe data source</a></span></dt><dt><span class="sect2"><a href="#live-updates">3.8. Live index updates</a></span></dt></dl></dd><dt><span class="sect1"><a href="#searching">4. Searching</a></span></dt><dd><dl><dt><span class="sect2"><a href="#matching-modes">4.1. Matching modes</a></span></dt><dt><span class="sect2"><a href="#boolean-syntax">4.2. Boolean query syntax</a></span></dt><dt><span class="sect2"><a href="#extended-syntax">4.3. Extended query syntax</a></span></dt><dt><span class="sect2"><a href="#weighting">4.4. Weighting</a></span></dt><dt><span class="sect2"><a href="#sorting-modes">4.5. Sorting modes</a></span></dt><dt><span class="sect2"><a href="#clustering">4.6. Grouping (clustering) search results </a></span></dt><dt><span class="sect2"><a href="#distributed">4.7. Distributed searching</a></span></dt></dl></dd><dt><span class="sect1"><a href="#sphinxse">5. MySQL storage engine (SphinxSE)</a></span></dt><dd><dl><dt><span class="sect2"><a href="#sphinxse-overview">5.1. SphinxSE overview</a></span></dt><dt><span class="sect2"><a href="#sphinxse-installing">5.2. Installing SphinxSE</a></span></dt><dd><dl><dt><span class="sect3"><a href="#sphinxse-mysql50">5.2.1. Compiling MySQL 5.0.x with SphinxSE</a></span></dt><dt><span class="sect3"><a href="#sphinxse-mysql51">5.2.2. Compiling MySQL 5.1.x with SphinxSE</a></span></dt><dt><span class="sect3"><a href="#sphinxse-checking">5.2.3. Checking SphinxSE installation</a></span></dt></dl></dd><dt><span class="sect2"><a href="#sphinxse-using">5.3. Using SphinxSE</a></span></dt></dl></dd><dt><span class="sect1"><a href="#reporting-bugs">6. Reporting bugs</a></span></dt><dt><span class="sect1"><a href="#reference">7. <code class="filename">sphinx.conf</code> options reference</a></span></dt><dd><dl><dt><span class="sect2"><a href="#ref-source">7.1. Data source configuration options</a></span></dt><dd><dl><dt><span class="sect3"><a href="#ref-source-type">7.1.1. type</a></span></dt><dt><span class="sect3"><a href="#ref-strip-html">7.1.2. strip_html</a></span></dt><dt><span class="sect3"><a href="#ref-index-html-attrs">7.1.3. index_html_attrs</a></span></dt><dt><span class="sect3"><a href="#ref-sql-host">7.1.4. sql_host</a></span></dt><dt><span class="sect3"><a href="#ref-sql-port">7.1.5. sql_port</a></span></dt><dt><span class="sect3"><a href="#ref-sql-user">7.1.6. sql_user</a></span></dt><dt><span class="sect3"><a href="#ref-sql-pass">7.1.7. sql_pass</a></span></dt><dt><span class="sect3"><a href="#ref-sql-db">7.1.8. sql_db</a></span></dt><dt><span class="sect3"><a href="#ref-sql-sock">7.1.9. sql_sock</a></span></dt><dt><span class="sect3"><a href="#ref-sql-query-pre">7.1.10. sql_query_pre</a></span></dt><dt><span class="sect3"><a href="#ref-sql-query">7.1.11. sql_query</a></span></dt><dt><span class="sect3"><a href="#ref-sql-query-range">7.1.12. sql_query_range</a></span></dt><dt><span class="sect3"><a href="#ref-sql-range-step">7.1.13. sql_range_step</a></span></dt><dt><span class="sect3"><a href="#ref-sql-group-column">7.1.14. sql_group_column</a></span></dt><dt><span class="sect3"><a href="#ref-sql-date-column">7.1.15. sql_date_column</a></span></dt><dt><span class="sect3"><a href="#ref-sql-str2ordinal-column">7.1.16. sql_str2ordinal_column</a></span></dt><dt><span class="sect3"><a href="#ref-sql-query-post">7.1.17. sql_query_post</a></span></dt><dt><span class="sect3"><a href="#ref-sql-query-post-index">7.1.18. sql_query_post_index</a></span></dt><dt><span class="sect3"><a href="#ref-sql-query-info">7.1.19. sql_query_info</a></span></dt><dt><span class="sect3"><a href="#ref-xmlpipe-command">7.1.20. xmlpipe_command</a></span></dt></dl></dd></dl></dd><dt><span class="appendix"><a href="#changelog">A. Sphinx revision history</a></span></dt></dl></div><div class="sect1" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="intro"></a>1.&nbsp;Introduction</h2></div></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="about"></a>1.1.&nbsp;About</h3></div></div></div><p>
Sphinx is a full-text search engine, distributed under GPL version 2.
Commercial licensing (eg. for embedded use) is also available upon request. 
</p><p>
Generally, it's a standalone search engine, meant to provide fast,
size-efficient and relevant full-text search functions to other
applications. Sphinx was specially designed to integrate well with
SQL databases and scripting languages.
</p><p>
Currently built-in data source drivers support fetching data either via
direct connection to MySQL, or PostgreSQL, or from a pipe in a custom XML
format. Adding new drivers (eg. to natively support some other DBMS)
is designed to be as easy as possible.
</p><p>
Search API is natively ported to PHP, Python, Perl and Ruby and
also available as a pluggable MySQL storage engine. API is very
lightweight so porting it to new language is known to take a few hours.
</p><p>
As for the name, Sphinx is an acronym which is officially decoded
as SQL Phrase Index. Yes, I know about CMU's Sphinx project. 
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="features"></a>1.2.&nbsp;Sphinx features</h3></div></div></div><p>
</p><div class="itemizedlist"><ul type="disc"><li>high indexing speed (upto 10 MB/sec on modern CPUs);</li><li>high search speed (avg query is under 0.1 sec on 2-4 GB text collections);</li><li>high scalability (upto 100 GB of text, upto 100 M documents on a single CPU);</li><li>provides good relevance ranking through combination of phrase proximity ranking and statistical (BM25) ranking;</li><li>provides distributed searching capabilities;</li><li>provides document exceprts generation;</li><li>provides searching from within MySQL through pluggable storage engine;</li><li>supports boolean, phrase, and word proximity queries;</li><li>supports multiple full-text fields per document (upto 32 by default);</li><li>supports multiple additional attributes per document (ie. groups, timestamps, etc);</li><li>supports stopwords;</li><li>supports both single-byte encodings and UTF-8;</li><li>supports English stemming, Russian stemming, and Soundex for morphology;</li><li>supports MySQL natively (MyISAM and InnoDB tables are both supported);</li><li>supports PostgreSQL natively.</li></ul></div><p>
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="getting"></a>1.3.&nbsp;Where to get Sphinx</h3></div></div></div><p>Sphinx is available through its official Web site at <a href="http://www.sphinxsearch.com/" target="_top">http://www.sphinxsearch.com/</a>.
</p><p>Currently, Sphinx distribution tarball includes the following software:
</p><div class="itemizedlist"><ul type="disc"><li><code class="filename">indexer</code>: an utility which creates fulltext indexes;</li><li><code class="filename">search</code>: a simple command-line (CLI) test utility which searches through fulltext indexes;</li><li><code class="filename">searchd</code>: a daemon which enables external software (eg. Web applications) to search through fulltext indexes;</li><li><code class="filename">sphinxapi</code>: a set of searchd client API libraries for popular Web scripting languages (PHP, Python, Perl, Ruby).</li></ul></div><p>
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="license"></a>1.4.&nbsp;License</h3></div></div></div><p>
This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License,
or (at your option) any later version. See COPYING file for details.
</p><p>
This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for
more details. 
</p><p>
You should have received a copy of the GNU General Public License
along with this program; if not, write to the Free Software Foundation, Inc.,
59 Temple Place, Suite 330, Boston, MA 02111-1307 USA 
</p><p>
If you don't want to be bound by GNU GPL terms (for instance,
if you would like to embed Sphinx in your software, but would not
like to disclose its source code), please contact
<a href="#author" title="1.5.&nbsp;Author and contributors">the author</a> to obtain
a commercial license.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="author"></a>1.5.&nbsp;Author and contributors</h3></div></div></div><h4><a name="id344157"></a>Author</h4><p>
Sphinx initial author and current primary developer is:
</p><div class="itemizedlist"><ul type="disc"><li>Andrew Aksyonoff, <code class="email">&lt;<a href="mailto:shodan(at)shodan.ru">shodan(at)shodan.ru</a>&gt;</code></li></ul></div><p>
</p><h4><a name="id343897"></a>Contributors</h4><p>People who contributed to Sphinx and their contributions (in no particular order) are:
</p><div class="itemizedlist"><ul type="disc"><li>Robert "coredev" Bengtsson (Sweden), initial version of PostgreSQL data source;</li><li>Len Kranendonk, Perl API</li><li>Dmytro Shteflyuk, Ruby API</li></ul></div><p>
</p><p>
Many other people have contributed ideas, bug reports, fixes, etc.
Thank you!
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="history"></a>1.6.&nbsp;History</h3></div></div></div><p>
Sphinx development was started back in 2001, because I didn't manage
to find an acceptable search solution (for a database driven Web site)
which would meet my requirements. Actually, each and every important aspect was a problem: 
</p><div class="itemizedlist"><ul type="disc"><li>search quality (ie. good relevance)
<div class="itemizedlist"><ul type="circle"><li>statistical ranking methods performed rather bad, especially on large collections of small documents (forums, blogs, etc)</li></ul></div></li><li>search speed
<div class="itemizedlist"><ul type="circle"><li>especially if searching for phrases which contain stopwords, as in "to be or not to be"</li></ul></div></li><li>moderate disk and CPU requirements when indexing
<div class="itemizedlist"><ul type="circle"><li>important in shared hosting enivronment, not to mention the indexing speed.</li></ul></div></li></ul></div><p>
</p><p>
Despite the amount of time passed and numerous improvements made in the
other solutions, there's still no solution which I personally would
be eager to migrate to. 
</p><p>
Considering that and a lot of positive feedback received from Sphinx users
during last years, the obvious decision is to continue developing Sphinx
(and, eventually, to take over the world).
</p></div></div><div class="sect1" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="installation"></a>2.&nbsp;Installation</h2></div></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="supported-system"></a>2.1.&nbsp;Supported systems</h3></div></div></div><p>
Most modern UNIX systems with a C++ compiler should be able
to compile and run Sphinx without any modifications.
</p><p>
Currently known systems Sphinx has been successfully running on are:
</p><div class="itemizedlist"><ul type="disc"><li>Linux 2.4.x, 2.6.x (various distributions)</li><li>Windows 2000, XP</li><li>FreeBSD 4.x, 5.x, 6.x</li><li>NetBSD 1.6</li><li>Solaris 9</li></ul></div><p>
</p><p>
I hope Sphinx will work on other Unix platforms as well. 
If the platform you run Sphinx on is not in this list,
please do report it.
</p><p>
At the moment, Windows version of Sphinx's <code class="filename">searchd</code>
daemon is not intended to be used in production because it can only handle
one client at a time.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="required-tools"></a>2.2.&nbsp;Required tools</h3></div></div></div><p>
On UNIX, you will need the following tools to build
and install Sphinx:
</p><div class="itemizedlist"><ul type="disc"><li>a working C++ compiler. GNU gcc is known to work.</li><li>a good make program. GNU make is known to work.</li></ul></div><p>
</p><p>
On Windows, you will need Microsoft Visual C/C++ Studio .NET 2003 or 2005.
Other compilers/environments will probably work as well, but for the
time being, you will have to build makefile (or other environment
specific project files) manually.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="installing"></a>2.3.&nbsp;Installing Sphinx</h3></div></div></div><div class="orderedlist"><ol type="1"><li><p>
	Extract everything from the distribution tarball (haven't you already?)
	and go to the <code class="filename">sphinx</code> subdirectory:
	</p><p><strong class="userinput"><code><div class="literallayout"><p>$&nbsp;tar&nbsp;xzvf&nbsp;sphinx-0.9.7.tar.gz<br>
$&nbsp;cd&nbsp;sphinx<br>
</p></div></code></strong></p></li><li><p>Run the configuration program:</p><p><strong class="userinput"><code><div class="literallayout"><p>$&nbsp;./configure</p></div></code></strong></p><p>
	There's a number of options to configure. The complete listing may
	be obtained by using <code class="option">--help</code> switch. The most important ones are:
	</p><div class="itemizedlist"><ul type="disc"><li><code class="option">--prefix</code>, which specifies where to install Sphinx;</li><li><code class="option">--with-mysql</code>, which specifies where to look for MySQL
			include and library files, if auto-detection fails;</li><li><code class="option">--with-pgsql</code>, which specifies where to look for PostgreSQL
			include and library files.</li></ul></div><p>
	</p></li><li><p>Build the binaries:</p><p><strong class="userinput"><code><div class="literallayout"><p>$&nbsp;make</p></div></code></strong></p></li><li><p>Install the binaries in the directory of your choice:</p><p><strong class="userinput"><code><div class="literallayout"><p>$&nbsp;make&nbsp;install</p></div></code></strong></p></li></ol></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="install-problems"></a>2.4.&nbsp;Known installation issues</h3></div></div></div><p>
If <code class="filename">configure</code> fails to locate MySQL headers and/or libraries,
try checking for and installing <code class="filename">mysql-devel</code> package. On some systems,
it is not installed by default.
</p><p>
If <code class="filename">make</code> fails with a message which look like
</p><pre class="programlisting">
/bin/sh: g++: command not found
make[1]: *** [libsphinx_a-sphinx.o] Error 127
</pre><p>
try checking for and installing <code class="filename">gcc-c++</code> package.
</p><p>
If you are getting compile-time errors which look like
</p><pre class="programlisting">
sphinx.cpp:67: error: invalid application of `sizeof' to
    incomplete type `Private::SizeError&lt;false&gt;'
</pre><p>
this means that some compile-time type size check failed.
The most probable reason is that off_t type is less than 64-bit
on your system. As a quick hack, you can edit sphinx.h and replace off_t
with DWORD in a typedef for SphOffset_t, but note that this will prohibit
you from using full-text indexes larger than 2 GB. Even if the hack helps,
please report such issues, providing the exact error message and
compiler/OS details, so I could properly fix them in next releases.
</p><p>
If you keep getting any other error, or the suggestions above
do not seem to help you, please don't hesitate to contact me.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="quick-tour"></a>2.5.&nbsp;Quick Sphinx usage tour</h3></div></div></div><p>
All the example commands below assume that you installed Sphinx
in <code class="filename">/usr/local/sphinx</code>.
</p><p>
To use Sphinx, you will need to:
</p><div class="orderedlist"><ol type="1"><li><p>Create a configuration file.</p><p>
	Default configuration file name is <code class="filename">sphinx.conf</code>.
	All Sphinx programs look for this file in current working directory
	by default.
	</p><p>
	Sample configuration file, <code class="filename">sphinx.conf.dist</code>, which has
	all the options documented, is created by <code class="filename">configure</code>.
	Copy and edit that sample file to make your own configuration:
	</p><p><strong class="userinput"><code><div class="literallayout"><p>$&nbsp;cd&nbsp;/usr/local/sphinx/etc<br>
$&nbsp;cp&nbsp;sphinx.conf.dist&nbsp;sphinx.conf<br>
$&nbsp;vi&nbsp;sphinx.conf</p></div></code></strong></p><p>
	Sample configuration file is setup to index <code class="filename">documents</code>
	table from MySQL database <code class="filename">test</code>; so there's <code class="filename">example.sql</code>
	sample data file to populate that table with a few documents for testing purposes:
	</p><p><strong class="userinput"><code><div class="literallayout"><p>$&nbsp;mysql&nbsp;-u&nbsp;test&nbsp;&lt;&nbsp;/usr/local/sphinx/etc/example.sql</p></div></code></strong></p></li><li><p>Run the indexer to create full-text index from your data:</p><p><strong class="userinput"><code><div class="literallayout"><p>$&nbsp;cd&nbsp;/usr/local/sphinx/etc<br>
$&nbsp;/usr/local/sphinx/bin/indexer</p></div></code></strong></p></li><li><p>Query your newly created index!</p></li></ol></div><p>
To query the index from command line, use <code class="filename">search</code> utility:
</p><p><strong class="userinput"><code><div class="literallayout"><p>$&nbsp;cd&nbsp;/usr/local/sphinx/etc<br>
$&nbsp;/usr/local/sphinx/bin/search&nbsp;test</p></div></code></strong></p><p>
To query the index from your PHP scripts, you need to:
</p><div class="orderedlist"><ol type="1"><li><p>Run the search daemon which your script will talk to:</p><p><strong class="userinput"><code><div class="literallayout"><p>$&nbsp;cd&nbsp;/usr/local/sphinx/etc<br>
$&nbsp;/usr/local/sphinx/bin/searchd</p></div></code></strong></p></li><li><p>
		Run the attached PHP API test script (to ensure that the daemon
		was succesfully started and is ready to serve the queries):
		</p><p><strong class="userinput"><code><div class="literallayout"><p>$&nbsp;cd&nbsp;sphinx/api<br>
$&nbsp;php&nbsp;test.php&nbsp;test</p></div></code></strong></p></li><li><p>
		Include the API (it's located in <code class="filename">api/sphinxapi.php</code>)
		into your own scripts and use it.
		</p></li></ol></div><p>
Happy searching!
</p></div></div><div class="sect1" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="indexing"></a>3.&nbsp;Indexing</h2></div></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="sources"></a>3.1.&nbsp;Data sources</h3></div></div></div><p>
The data to be indexed can generally come from very different
sources: SQL databases, plain text files, HTML files, mailboxes,
and so on. From Sphinx point of view, the data it indexes is a
set of structured <em class="glossterm">documents</em>, each of which has the
same set of <em class="glossterm">fields</em>. This is biased towards SQL, where
each row correspond to a document, and each column to a field.
</p><p>
Depending on what source Sphinx should get the data from,
different code is required to fetch the data and prepare it for indexing.
This code is called <em class="glossterm">data source driver</em> (or simply
<em class="glossterm">driver</em> or <em class="glossterm">data source</em> for brevity).
</p><p>
At the time of this writing, there are drivers for MySQL and
PostgreSQL databases, which can connect to the database using
its native C/C++ API, run queries and fetch the data. There's
also a driver called XMLpipe, which runs a specified command
and reads the data from its <code class="filename">stdout</code>.
See <a href="#xmlpipe" title="3.7.&nbsp;XMLpipe data source">Section&nbsp;3.7, &#8220;XMLpipe data source&#8221;</a> section for the format description.
</p><p>
There can be as many sources per index as necessary. They will be
sequentially processed in the very same order which was specifed in
index definition. All the documents coming from those sources
will be merged as if they were coming from a single source.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="attributes"></a>3.2.&nbsp;Attributes</h3></div></div></div><p>
It is often needed to do some additional processing of full-text
search results depending not only on matching document ID and weight,
but on a number of other per-document values as well.
For instance, one might need to
sort news search results by date and then relevance,
or search through products within specified price range,
or limit blog search to posts made by selected users,
or group results by month.
</p><p>
To do that efficiently, Sphinx allows to attach a number
of additional <em class="glossterm">attributes</em> to each document, and stores their
values when indexing. These values may then be used to filter,
sort, or group full-text matches when searching.
</p><p>
A good example would be a forum posts table. Assume that
'title' and 'content' fields need to be full-text searchable,
but it is also needed to optionally limit searching to some author
or sub-forum (ie. specific values of 'author_id' or 'forum_id'),
or to sort matches by 'post_date', or to group matching posts
by month of the 'post_date' and calculate per-group match counts.
</p><p>
This can be achieved by specifying all the mentioned columns
(excluding 'title' and 'content' which are full-text fields) as
attributes and then using API calls to setup filtering, sorting,
and grouping. Here as an example.
</p><h4><a name="id350704"></a>Example sphinx.conf part:</h4><p>
</p><pre class="programlisting">
...
sql_query = SELECT id, title, content, \
	author_id, forum_id, post_date FROM my_forum_posts
sql_group_column = author_id
sql_group_column = forum_id
sql_date_column = post_date
...
</pre><p>
</p><h4><a name="id350716"></a>Example application code (in PHP):</h4><p>
</p><pre class="programlisting">
// only search posts by author whose ID is 123
$cl-&gt;SetFilter ( "author_id", array ( 123 ) );

// only search posts in sub-forums 1, 3 and 7
$cl-&gt;SetFilter ( "forum_id", array ( 1,3,7 ) );

// sort found posts by posting date in descending order
$cl-&gt;SetSortMode ( SPH_ATTR_DESC, "post_date" );
</pre><p>
</p><p>
Attributes are named. Attribute names are case insensitive.
</p><p>
Attributes are <span class="emphasis"><em>not</em></span> full-text indexed;
they are stored in the index as is.
</p><p>
Currently supported attribute types are:
</p><div class="itemizedlist"><ul type="disc"><li>32-bit unsigned integer,</li><li>UNIX timestamp.</li></ul></div><p>
</p><p>
Attribute values are currently internally stored as fixed-size
4-byte values. A set of all per-document attribute values is called <em class="glossterm">docinfo</em>.
Docinfos can either be
</p><div class="itemizedlist"><ul type="disc"><li>stored separately ("extern" storage in <code class="filename">.spa</code> file), or</li><li>attached to each occurence of document ID in full-text index data
("inline" storage in <code class="filename">.spd</code> file).</li></ul></div><p>
</p><p>
Externally stored docinfo is kept in RAM when searching. Thus
"inline" may be the only viable option for huge (50-100+ million
documents) datasets because of limited RAM size. However, for
smaller datasets "extern" storage makes both indexing and
searching <span class="emphasis"><em>much</em></span> more efficient.
</p><p>
Additional search-time memory requirements for extern storage are
(1+number_of_attrs)*number_of_docs*4 bytes, ie. 10 million docs with
2 groups and 1 timestamp will take (1+2+1)*10M*4 = 160 MB of RAM.
This is <span class="emphasis"><em>PER DAEMON</em></span>, ie. searchd
will alloc 160 MB on startup, read the data and keep it shared
between queries; the children will <span class="emphasis"><em>NOT</em></span> allocate additional
copies of this data.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="indexes"></a>3.3.&nbsp;Indexes</h3></div></div></div><p>
To be able to answer full-text search queries fast, Sphinx needs
to build a special data structure optimized for such queries from
your text data. This structure is called <em class="glossterm">index</em>; and
the process of building index from text is called <em class="glossterm">indexing</em>.
</p><p>
Different index types are well suited for different tasks.
For example, a disk-based tree-based index would be easy to
update (ie. insert new documents to existing index), but rather
slow to search. Therefore, Sphinx architecture allows for different
<em class="glossterm">index types</em> to be implemented easily.
</p><p>
The only index type which is implemented in Sphinx at the moment is
designed for maximum indexing and searching speed. This comes at a cost
of updates being really slow; theoretically, it might be slower to
update this type of index than than to reindex it from scratch.
However, this very frequently could be worked around with
muiltiple indexes, see <a href="#live-updates" title="3.8.&nbsp;Live index updates">Section&nbsp;3.8, &#8220;Live index updates&#8221;</a> for details.
</p><p>
It is planned to implement more index types, including the
type which would be updateable in real time.
</p><p>
There can be as many indexes per configuration file as necessary.
<code class="filename">indexer</code> utility can reindex either all of them
(if <code class="option">--all</code> option is specified), or a certain explicitly
specified subset. <code class="filename">searchd</code> utility will serve all
the specified indexes, and the clients can specify what indexes to
search in run time.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="data-restrictions"></a>3.4.&nbsp;Restrictions on the source data</h3></div></div></div><p>
There are a few different restrictions imposed on the source data
which is going to be indexed by Sphinx, of which the single most
important one is:
</p><p><span class="bold"><strong>
ALL DOCUMENT IDS MUST BE UNIQUE UNSIGNED NON-ZERO 32-BIT INTEGER NUMBERS.
</strong></span></p><p>
If this requirement is not met, different bad things can happen.
For instance, Sphinx can crash with an internal assertion while indexing;
or produce strange results when searching due to conflicting IDs.
Also, a 1000-pound gorilla might eventually come out of your
display and start throwing barrels at you. You've been warned.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="charsets"></a>3.5.&nbsp;Charsets, case folding, and translation tables</h3></div></div></div><p>
When indexing some index, Sphinx fetches documents from
the specified sources, splits the text into words, and does
case folding so that "Abc", "ABC" and "abc" would be treated
as the same word (or, to be pedantic, <em class="glossterm">term</em>).
</p><p>
To do that properly, Sphinx needs to know
</p><div class="itemizedlist"><ul type="disc"><li>what encoding is the source text in;</li><li>what characters are letters and what are not;</li><li>what letters should be folded to what letters.</li></ul></div><p>
This should be configured on a per-index basis using
<code class="option">charset_type</code> and 
<code class="option">charset_table</code> options.
With <code class="option">charset_type</code>,
one would specify whether the document encoding is single-byte (SBCS) or UTF-8.
<code class="option">charset_table</code> would
then be used to specify the table which maps letter characters to their case
folded versions. The characters which are not in the table are considered
to be non-letters and will be treated as word separators when indexing
or searching through this index.
</p><p>
Note that while default tables do not include space character
(ASCII code 0x20, Unicode U+0020) as a letter, it's in fact
<span class="emphasis"><em>perfectly legal</em></span> to do so. This can be
useful, for instance, for indexing tag clouds, so that space-separated
word sets would index as a <span class="emphasis"><em>single</em></span> search query term.
</p><p>
Default tables currently include English and Russian characters.
Please do submit your tables for other languages!
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="sql"></a>3.6.&nbsp;SQL data sources (MySQL, PostgreSQL)</h3></div></div></div><p>
With all the SQL drivers, indexing generally works as follows.
</p><div class="itemizedlist"><ul type="disc"><li>connection to the database is established;</li><li>pre-query (see <a href="#ref-sql-query-pre" title="7.1.10.&nbsp;sql_query_pre">Section&nbsp;7.1.10, &#8220;sql_query_pre&#8221;</a>) is executed
	to perform any necessary initial setup, such as setting per-connection encoding with MySQL;</li><li>main query (see <a href="#ref-sql-query" title="7.1.11.&nbsp;sql_query">Section&nbsp;7.1.11, &#8220;sql_query&#8221;</a>) is executed and the rows it returns are indexed;</li><li>post-query (see <a href="#ref-sql-query-post" title="7.1.17.&nbsp;sql_query_post">Section&nbsp;7.1.17, &#8220;sql_query_post&#8221;</a>) is executed
	to perform any necessary cleanup;</li><li>connection to the database is closed;</li><li>indexer does the sorting phase (to be pedantic, index-type specific post-processing);</li><li>connection to the database is established again;</li><li>post-index query (see <a href="#ref-sql-query-post-index" title="7.1.18.&nbsp;sql_query_post_index">Section&nbsp;7.1.18, &#8220;sql_query_post_index&#8221;</a>) is executed
	to perform any necessary final cleanup;</li><li>connection to the database is closed again.</li></ul></div><p>
Most options, such as database user/host/password, are straightforward.
However, there are a few subtle things, which are discussed in more detail here.
</p><h4><a name="ranged-queries"></a>Ranged queries</h4><p>
Main query, which needs to fetch all the documents, can impose
a read lock on the whole table and stall the concurrent queries
(eg. INSERTs to MyISAM table), waste a lot of memory for result set, etc.
To avoid this, Sphinx supports so-called <em class="glossterm">ranged queries</em>.
With ranged queries, Sphinx first fetches min and max document IDs from
the table, and then substitutes different ID intervals into main query text
and runs the modified query to fetch another chunk of documents.
Here's an example.
</p><div class="example"><a name="ex-ranged-queries"></a><p class="title"><b>Example&nbsp;1.&nbsp;Ranged query usage example</b></p><div class="example-contents"><pre class="programlisting">
# in sphinx.conf

sql_query_range	= SELECT MIN(id),MAX(id) FROM documents
sql_range_step = 1000
sql_query = SELECT * FROM documents WHERE id&gt;=$start AND id&lt;=$end
</pre></div></div><br class="example-break"><p>
If the table contains document IDs from 1 to, say, 2345, then sql_query would
be run three times:
</p><div class="orderedlist"><ol type="1"><li>with <code class="option">$start</code> replaced with 1 and <code class="option">$end</code> replaced with 1000;</li><li>with <code class="option">$start</code> replaced with 1001 and <code class="option">$end</code> replaced with 2000;</li><li>with <code class="option">$start</code> replaced with 2000 and <code class="option">$end</code> replaced with 2345.</li></ol></div><p>
Obviously, that's not much of a difference for 2000-row table,
but when it comes to indexing 10-million-row MyISAM table,
ranged queries might be of some help.
</p><h4><a name="id351272"></a><code class="option">sql_post</code> vs. <code class="option">sql_post_index</code></h4><p>
The difference between post-query and post-index query is in that post-query
is run immediately when Sphinx received all the documents, but further indexing
<span class="bold"><strong>may</strong></span> still fail for some other reason. On the contrary,
by the time the post-index query gets executed, it is <span class="bold"><strong>guaranteed</strong></span>
that the indexing was succesful. Database connection is dropped and re-established
because sorting phase can be very lengthy and would just timeout otherwise.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="xmlpipe"></a>3.7.&nbsp;XMLpipe data source</h3></div></div></div><p>
XMLpipe data source is designed to enable users to plug data into
Sphinx without having to implement new data sources drivers themselves.
</p><p>
To use XMLpipe, configure the data source in your configuration file
as follows:
</p><pre class="programlisting">
source example_xmlpipe_source
{
    type = xmlpipe
    xmlpipe_command = perl /www/mysite.com/bin/sphinxpipe.pl
}
</pre><p>
The <code class="filename">indexer</code> will run the command specified
in <code class="option"><a href="#ref-xmlpipe-command" title="7.1.20.&nbsp;xmlpipe_command">xmlpipe_command</a></code>,
and then read, parse and index the data it prints to <code class="filename">stdout</code>.
</p><p>
XMLpipe driver expects the data to be in special XML format.
Here's the example document stream, consisting of two documents:
</p><div class="example"><a name="ex-xmlpipe-document"></a><p class="title"><b>Example&nbsp;2.&nbsp;XMLpipe document stream</b></p><div class="example-contents"><pre class="programlisting">
&lt;document&gt;
&lt;id&gt;123&lt;/id&gt;
&lt;group&gt;45&lt;/group&gt;
&lt;timestamp&gt;1132223498&lt;/timestamp&gt;
&lt;title&gt;test title&lt;/title&gt;
&lt;body&gt;
this is my document body
&lt;/body&gt;
&lt;/document&gt;

&lt;document&gt;
&lt;id&gt;124&lt;/id&gt;
&lt;group&gt;46&lt;/group&gt;
&lt;timestamp&gt;1132223498&lt;/timestamp&gt;
&lt;title&gt;another test&lt;/title&gt;
&lt;body&gt;
this is another document
&lt;/body&gt;
&lt;/document&gt;
</pre></div></div><p><br class="example-break">
</p><p>
At the moment, the driver is using a custom manually written parser
which is pretty fast but really strict; so almost all the fields <span class="emphasis"><em>must</em></span>
be present, formatted <span class="emphasis"><em>exactly</em></span> as in this example, and
occur <span class="emphasis"><em>exactly</em></span> in this order. The only optional field
is <code class="option">timestamp</code>; it's set to 1 if it's missing.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="live-updates"></a>3.8.&nbsp;Live index updates</h3></div></div></div><p>
There's a frequent situation when the total dataset is too big
to be reindexed from scratch often, but the amount of new records
is rather small. Example: a forum with a 1,000,000 archived posts,
but only 1,000 new posts per day.
</p><p>
In this case, "live" (almost real time) index updates could be
implemented using so called "main+delta" scheme.
</p><p>
The idea is to set up two sources and two indexes, with one
"main" index for the data which only changes rarely (if ever),
and one "delta" for the new documents. In the example above,
1,000,000 archived posts would go to the main index, and newly
inserted 1,000 posts/day would go to the delta index. Delta index
could then be reindexed very frequently, and the documents can
be made available to search in a matter of minutes.
</p><p>
Specifying which documents should go to what index and
reindexing main index could also be made fully automatical.
One option would be to make a counter table which would track
the ID which would split the documents, and update it
whenever the main index is reindexed.
</p><div class="example"><a name="ex-live-updates"></a><p class="title"><b>Example&nbsp;3.&nbsp;Fully automated live updates</b></p><div class="example-contents"><pre class="programlisting">
# in MySQL
CREATE TABLE sph_counter
(
    counter_id INTEGER PRIMARY KEY NOT NULL,
    max_doc_id INTEGER NOT NULL
);

# in sphinx.conf
source main
{
    # ...
    sql_query_pre = REPLACE INTO sph_counter SELECT 1, MAX(id) FROM documents
    sql_query = SELECT id, title, body FROM documents \
        WHERE id&lt;=( SELECT max_doc_id FROM sph_counter WHERE counter_id=1 )
}

source delta : main
{
    sql_query_pre =
    sql_query = SELECT id, title, body FROM documents \
        WHERE id&gt;( SELECT max_doc_id FROM sph_counter WHERE counter_id=1 )
}
</pre></div></div><p><br class="example-break">
</p></div></div><div class="sect1" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="searching"></a>4.&nbsp;Searching</h2></div></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="matching-modes"></a>4.1.&nbsp;Matching modes</h3></div></div></div><p>
There are the following matching modes available:
</p><div class="itemizedlist"><ul type="disc"><li>SPH_MATCH_ALL, matches all query words (default mode);</li><li>SPH_MATCH_ANY, matches any of the query words;</li><li>SPH_MATCH_PHRASE, matches query as a phrase, requiring perfect match;</li><li>SPH_MATCH_BOOLEAN, matches query as a boolean expression (see <a href="#boolean-syntax" title="4.2.&nbsp;Boolean query syntax">Section&nbsp;4.2, &#8220;Boolean query syntax&#8221;</a>);</li><li>SPH_MATCH_EXTENDED, matches query as an expression in Sphinx internal query language (see <a href="#extended-syntax" title="4.3.&nbsp;Extended query syntax">Section&nbsp;4.3, &#8220;Extended query syntax&#8221;</a>).</li></ul></div><p>
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="boolean-syntax"></a>4.2.&nbsp;Boolean query syntax</h3></div></div></div><p>
Boolean queries allow the following special operators to be used:
</p><div class="itemizedlist"><ul type="disc"><li>explicit operator AND: <pre class="programlisting">hello &amp; world</pre></li><li>operator OR: <pre class="programlisting">hello | world</pre></li><li>operator NOT:
<pre class="programlisting">
hello -world
hello !world
</pre></li><li>grouping: <pre class="programlisting">( hello world )</pre></li></ul></div><p>
Here's an example query which uses all these operators:
</p><div class="example"><a name="ex-boolean-query"></a><p class="title"><b>Example&nbsp;4.&nbsp;Boolean query example</b></p><div class="example-contents"><pre class="programlisting">
( cat -dog ) | ( cat -mouse)
</pre></div></div><p><br class="example-break">
</p><p>
There always is implicit AND operator, so "hello world" query actually
means "hello &amp; world".
</p><p>
OR operator precedence is higher than AND, so "looking for cat | dog | mouse"
means "looking for ( cat | dog | mouse )" and <span class="emphasis"><em>not</em></span>
"(looking for cat) | dog | mouse".
</p><p>
Queries like "-dog", which implicitly include all documents from the
collection, can not be evaluated. This is both for technical and performance
reasons. Technically, Sphinx does not always keep a list of all IDs.
Performance-wise, when the collection is huge (ie. 10-100M documents),
evaluating such queries could take very long.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extended-syntax"></a>4.3.&nbsp;Extended query syntax</h3></div></div></div><p>
Extended queries allow the following special operators to be used:
</p><div class="itemizedlist"><ul type="disc"><li>operator OR: <pre class="programlisting">hello | world</pre></li><li>operator NOT:
<pre class="programlisting">
hello -world
hello !world
</pre></li><li>field search operator: <pre class="programlisting">@title hello @body world</pre></li><li>phrase search operator: <pre class="programlisting">"hello world"</pre></li><li>proximity search operator: <pre class="programlisting">"hello world"~10</pre></li></ul></div><p>

Here's an example query which uses all these operators:
</p><div class="example"><a name="ex-extended-query"></a><p class="title"><b>Example&nbsp;5.&nbsp;Extended query example</b></p><div class="example-contents"><pre class="programlisting">
"hello world" @title "example program"~5 @body python -(php|perl)
</pre></div></div><p><br class="example-break">
</p><p>
There always is implicit AND operator, so "hello world" means that
both "hello" and "world" must be present in matching document.
</p><p>
OR operator precedence is higher than AND, so "looking for cat | dog | mouse"
means "looking for ( cat | dog | mouse )" and <span class="emphasis"><em>not</em></span>
"(looking for cat) | dog | mouse".
</p><p>
Proximity distance is specified in words, adjusted for word count, and
applies to all words within quotes. For instance, "cat dog mouse"~5 query
means that there must be less than 8-word span which contains all 3 words,
ie. "CAT aaa bbb ccc DOG eee fff MOUSE" document will <span class="emphasis"><em>not</em></span>
match this query, because this span is exactly 8 words long.
</p><p>
Nested brackets, as in queries like
</p><pre class="programlisting">
aaa | ( bbb ccc | ( ddd eee ) )
</pre><p>
are not allowed yet, but this will be fixed.
</p><p>
Negation (ie. operator NOT) is only allowed on top level and not within
brackets (ie. groups). This isn't going to change, because supporting nested
negations would make phrase ranking implementation way too complicated.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="weighting"></a>4.4.&nbsp;Weighting</h3></div></div></div><p>
Specific weighting function (currently) depends on the search mode.
</p><p>
There are these major parts which are used in the weighting functions:
</p><div class="orderedlist"><ol type="1"><li>phrase rank,</li><li>statistical rank.</li></ol></div><p>
</p><p>
Phrase rank is based on a length of longest common subsequence
(LCS) of search words between document body and query phrase. So if
there's a perfect phrase match in some document then its phrase rank
would be the highest possible, and equal to query words count.
</p><p>
Statistical rank is based on classic BM25 function which only takes
word frequencies into account. If the word is rare in the whole database
(ie. low frequency over document collection) or mentioned a lot in specific
document (ie. high frequency over matching document), it receives more weight.
Final BM25 weight is a floating point number between 0 and 1.
</p><p>
In all modes, per-field weighted phrase ranks are computed as
a product of LCS multiplied by per-field weight speficifed by user.
Per-field weights are integer, default to 1, and can not be set
lower than 1.
</p><p>
In SPH_MATCH_BOOLEAN mode, no weighting is performed at all, every match weight
is set to 1.
</p><p>
In SPH_MATCH_ALL and SPH_MATCH_PHRASE modes, final weight is a sum of weighted phrase ranks.
</p><p>
In SPH_MATCH_ANY mode, the idea is essentially the same, but it also
adds a count of matching words in each field. Before that, weighted
phrase ranks are additionally mutliplied by a value big enough to
guarantee that higher phrase rank in <span class="bold"><strong>any</strong></span> field will make the
match ranked higher, even if it's field weight is low.
</p><p>
In SPH_MATCH_EXTENDED mode, final weight is a sum of weighted phrase
ranks and BM25 weight, multiplied by 1000 and rounded to integer.
</p><p>
This is going to be changed, so that MATCH_ALL and MATCH_ANY modes
use BM25 weights as well. This would improve search results in those
match spans where phrase ranks are equal; this is especially useful
for 1-word queries.
</p><p>
The key idea (in all modes, besides boolean) is that better subphrase
matches are ranked higher, and perfect matches are pulled to the top. Author's
experience is that this phrase proximity based ranking provides noticeably
better search quality than any statistical scheme alone (such as BM25,
which is commonly used in other search engines).
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="sorting-modes"></a>4.5.&nbsp;Sorting modes</h3></div></div></div><p>
There are the following result sorting modes available:
</p><div class="itemizedlist"><ul type="disc"><li>SPH_SORT_RELEVANCE, sorts by relevance in descending order (best matches first);</li><li>SPH_SORT_ATTR_DESC, sorts by attribute in descending order (bigger attribute values first);</li><li>SPH_SORT_ATTR_ASC, sorts by attribute in ascending order (smaller attribute values first);</li><li>SPH_SORT_TIME_SEGMENTS, sorts by time segments (last hour/day/week/month) in descending order, and then by relevance in descending order;</li><li>SPH_SORT_EXTENDED, sorts by SQL-like expression.</li></ul></div><p>
</p><p>
SPH_SORT_ATTR_ASC, SPH_SORT_ATTR_DESC and SPH_SORT_TIME_SEGMENTS modes
require an attribute to sort by to be specified.
</p><h4><a name="id351974"></a>SPH_SORT_TIME_SEGMENTS mode</h4><p>
In SPH_SORT_TIME_SEGMENTS mode, attribute values are split into so-called
time segments, and then sorted by time segment first, and by relevance second.
</p><p>
The segments are calculated according to the <span class="emphasis"><em>current timestamp</em></span>
at the time when the search is performed, so the results would change over time.
The segments are as follows:
</p><div class="itemizedlist"><ul type="disc"><li>last hour,</li><li>last day,</li><li>last week,</li><li>last month,</li><li>last 3 months,</li><li>everything else.</li></ul></div><p>
These segments are hardcoded, but it is trivial to change them if necessary.
</p><p>
This mode was added to support searching through blogs, news headlines, etc.
When using time segments, recent records would be ranked higher because of segment,
but withing the same segment, more relevant records would be ranked higher -
unlike sorting by just the timestamp attribute, which would not take relevance
into account at all.
</p><h4><a name="sort-extended"></a>SPH_SORT_EXTENDED mode</h4><p>
In SPH_SORT_EXTENDED mode, you would specify an SQL-like sort
expression to sort by:
</p><pre class="programlisting">
@relevance DESC, price ASC, @id DESC
</pre><p>
</p><p>
Both internal attributes (their names start with @) and externally
specified user attributes (their names are as is) can be allowed.
In the example above, <code class="option">@relevance</code> and <code class="option">@id</code>
are internal attributes and <code class="option">price</code> is user-speficied.
</p><p>
Known internal attributes are:
</p><div class="itemizedlist"><ul type="disc"><li>@id (match ID)</li><li>@rank (match weight)</li><li>@weight (match weight)</li><li>@relevance (match weight)</li></ul></div><p>
<code class="option">@rank</code>, <code class="option">@weight</code> and <code class="option">@relevance</code>
are just aliases; there's no actual difference between them.
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="clustering"></a>4.6.&nbsp;Grouping (clustering) search results </h3></div></div></div><p>
Sometimes it could be useful to group (or in other terms, cluster)
search results and/or count per-group match counts - for instance,
to draw a nice graph of how much maching blog posts were there per
each month; or to group Web search results by site; or to group
matching forum posts by author; etc.
</p><p>
In theory, this could be performed by doing only the full-text search
in Sphinx and then using found IDs to group on SQL server side. However,
in practice doing this with a big result set (10K-10M matches) would
typically kill performance.
</p><p>
To avoid that, Sphinx offers so-called grouping mode. It is enabled
with SetGroupBy() API call. When grouping, all matches are assigned to
different groups based on group-by value. This value is computed from
specified attribute using one of the following built-in functions:
</p><div class="itemizedlist"><ul type="disc"><li>SPH_GROUPBY_DAY, extracts year, month and day in YYYYMMDD format from timestamp;</li><li>SPH_GROUPBY_WEEK, extracts year and first day of the week number (counting from year start) in YYYYNNN format from timestamp;</li><li>SPH_GROUPBY_MONTH, extracts month in YYYYMM format from timestamp;</li><li>SPH_GROUPBY_YEAR, extracts year in YYYY format from timestamp;</li><li>SPH_GROUPBY_ATTR, uses attribute value itself for grouping.</li></ul></div><p>
</p><p>
The final search result set then contains one best match per group.
Grouping function value and per-group match count are returned along
as "virtual" attributes named
<span class="bold"><strong>@group</strong></span> and
<span class="bold"><strong>@count</strong></span> respectively.
</p><p>
The result set is sorted by group-by sorting clause, with the syntax similar
to <a href="#sort-extended"><code class="option">SPH_SORT_EXTENDED</code> sorting clause</a>
syntax. In addition to <code class="option">@id</code> and <code class="option">@weight</code>,
group-by sorting clause may also include:
</p><div class="itemizedlist"><ul type="disc"><li>@group (groupby function value),</li><li>@count (amount of matches in group).</li></ul></div><p>
</p><p>
The default mode is to sort by groupby value in descending order,
ie. by <code class="option">"@group desc"</code>.
</p><p>
On completion, <code class="option">total_found</code> result parameter would
contain total amount of matching groups over he whole index.
</p><p>
<span class="bold"><strong>WARNING:</strong></span> grouping is done in fixed memory
and thus its results are only approximate; so there might be more groups reported
in <code class="option">total_found</code> than actually present. <code class="option">@count</code> might also
be underestimated. To reduce inaccuracy, one should raise <code class="option">max_matches</code>.
If <code class="option">max_matches</code> allows to store all found groups, results will be 100% correct.
</p><p>
For example, if sorting by relevance and grouping by <code class="code">"published"</code>
attribute with <code class="code">SPH_GROUPBY_DAY</code> function, then the result set will
contain
</p><div class="itemizedlist"><ul type="disc"><li>one most relevant match per each day when there were any
matches published,</li><li>with day number and per-day match count attached,</li><li>sorted by day number in descending order (ie. recent days first).</li></ul></div><p>
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="distributed"></a>4.7.&nbsp;Distributed searching</h3></div></div></div><p>
To scale well, Sphinx has distributed searching capabilities.
Distributed searching is useful to improve query latency (ie. search
time) and throughput (ie. max queries/sec) in multi-server, multi-CPU
or multi-core environments. This is essential for applications which
need to search through huge amounts data (ie. billions of records
and terabytes of text).
</p><p>
The key idea is to horizontally partition (HP) searched data
accross search nodes and then process it in parallel.
</p><p>
Partitioning is done manually. You would
</p><div class="itemizedlist"><ul type="disc"><li>setup several instances
of Sphinx programs (<code class="filename">indexer</code> and <code class="filename">searchd</code>)
on different servers;</li><li>make the instances index (and search) different parts of data;</li><li>configure a special distributed index on some of the <code class="filename">searchd</code>
instances;</li><li>and query this index.</li></ul></div><p>
This index only contains references to other
local and remote indexes - so it could not be directly reindexed,
and you should reindex those indexes which it references instead.
</p><p>
When <code class="filename">searchd</code> receives a query against distributed index,
it does the following:
</p><div class="orderedlist"><ol type="1"><li>connects to configured remote agents;</li><li>issues the query;</li><li>sequentially searches configured local indexes (while the remote agents are searching);</li><li>retrieves remote agents' search results;</li><li>merges all the results together, removing the duplicates;</li><li>sends the merged resuls to client.</li></ol></div><p>
</p><p>
From the application's point of view, there are no differences
between usual and distributed index at all.
</p><p>
Any <code class="filename">searchd</code> instance could serve both as a master
(which aggregates the results) and a slave (which only does local searching)
at the same time. This has a number of uses:
</p><div class="orderedlist"><ol type="1"><li>every machine in a cluster could serve as a master which
searches the whole cluster, and search requests could be balanced between
masters to achieve a kind of HA (high availability) in case any of the nodes fails;
</li><li>
if running within a single multi-CPU or multi-core machine, there
would be only 1 searchd instance quering itself as an agent and thus
utilizing all CPUs/core.
</li></ol></div><p>
</p><p>
It is scheduled to implement better HA support which would allow
to specify which agents mirror each other, do health checks, keep track
of alive agents, load-balance requests, etc.
</p></div></div><div class="sect1" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxse"></a>5.&nbsp;MySQL storage engine (SphinxSE)</h2></div></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="sphinxse-overview"></a>5.1.&nbsp;SphinxSE overview</h3></div></div></div><p>
SphinxSE is MySQL storage engine which can be compiled
into MySQL server 5.x using its pluggable architecure.
It is not available for MySQL 4.x series. It also requires
MySQL 5.0.22 or higher in 5.0.x series, or MySQL 5.1.12
or higher in 5.1.x series.
</p><p>
Despite the name, SphinxSE does <span class="emphasis"><em>not</em></span>
actually store any data itself. It is actually a built-in client
which allows MySQL server to talk to <code class="filename">searchd</code>,
run search queries, and obtain search results. All indexing and
searching happen outside MySQL.
</p><p>
Obvious SphinxSE applications include:
</p><div class="itemizedlist"><ul type="disc"><li>easier porting of MySQL FTS applications to Sphinx;</li><li>allowing Sphinx use with progamming languages for which native APIs are not available yet;</li><li>optimizations when additional Sphinx result set processing on MySQL side is required
	(eg. JOINs with original document tables, additional MySQL-side filtering, etc).</li></ul></div><p>
</p></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="sphinxse-installing"></a>5.2.&nbsp;Installing SphinxSE</h3></div></div></div><p>
You will need to obtain a copy of MySQL sources, prepare those,
and then recompile MySQL binary.
MySQL sources (mysql-5.x.yy.tar.gz) could be obtained from 
<a href="http://dev.mysql.com" target="_top">dev.mysql.com</a> Web site.
</p><p>
For some MySQL versions, there are delta tarballs with already
prepared source versions available from Sphinx Web site. After unzipping
those over original sources MySQL would be ready to be configured and
built with Sphinx support.
</p><p>
If such tarball is not available, or does not work for you for any
reason, you would have to prepare sources manually. You will need to
GNU Autotools framework (autoconf, automake and libtool) installed
to do that.
</p><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="sphinxse-mysql50"></a>5.2.1.&nbsp;Compiling MySQL 5.0.x with SphinxSE</h4></div></div></div><p>
Skips steps 1-3 if using already prepared delta tarball.
</p><div class="orderedlist"><ol type="1"><li><p>copy <code class="filename">sphinx.5.0.yy.diff</code> patch file
into MySQL sources directory and run
</p><pre class="programlisting">
patch -p1 &lt; sphinx.5.0.yy.diff
</pre><p>
If there's no .diff file exactly for the specific version you need
to build, try applying .diff with closest version numbers. It is important
that the patch should apply with no rejects.
</p></li><li>in MySQL sources directory, run
<pre class="programlisting">
sh BUILD/autorun.sh
</pre></li><li>in MySQL sources directory, create <code class="filename">sql/sphinx</code>
directory in and copy all files in <code class="filename">mysqlse</code> directory 
from Sphinx sources there. Example:
<pre class="programlisting">
cp -R /root/builds/sphinx-0.9.7/mysqlse /root/builds/mysql-5.0.24/sql/sphinx
</pre></li><li>
configure MySQL and enable Sphinx engine:
<pre class="programlisting">
./configure --with-sphinx-storage-engine
</pre></li><li>
build and install MySQL:
<pre class="programlisting">
make
make install
</pre></li></ol></div></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="sphinxse-mysql51"></a>5.2.2.&nbsp;Compiling MySQL 5.1.x with SphinxSE</h4></div></div></div><p>
Skip steps 1-2 if using already prepared delta tarball.
</p><div class="orderedlist"><ol type="1"><li>in MySQL sources directory, create <code class="filename">storage/sphinx</code>
directory in and copy all files in <code class="filename">mysqlse</code> directory 
from Sphinx sources there. Example:
<pre class="programlisting">
cp -R /root/builds/sphinx-0.9.7/mysqlse /root/builds/mysql-5.1.14/storage/sphinx
</pre></li><li>in MySQL sources directory, run
<pre class="programlisting">
sh BUILD/autorun.sh
</pre></li><li>
configure MySQL and enable Sphinx engine:
<pre class="programlisting">
./configure --with-plugins=sphinx
</pre></li><li>
build and install MySQL:
<pre class="programlisting">
make
make install
</pre></li></ol></div></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="sphinxse-checking"></a>5.2.3.&nbsp;Checking SphinxSE installation</h4></div></div></div>
To check whether SphinxSE has been succesfully compiled
into MySQL, launch newly built servers, run mysql client and
issue <code class="code">SHOW ENGINES</code> query. You should see a list
of all available engines. Sphinx should be present and "Support"
column should contain "YES":

<pre class="programlisting">     
mysql&gt; show engines;
+------------+----------+----------------------------------------------------------------+
| Engine     | Support  | Comment                                                        |
+------------+----------+----------------------------------------------------------------+
| MyISAM     | DEFAULT  | Default engine as of MySQL 3.23 with great performance         |
  ...
| SPHINX     | YES      | Sphinx storage engine                                          |
  ...
+------------+----------+----------------------------------------------------------------+
13 rows in set (0.00 sec)    
</pre></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="sphinxse-using"></a>5.3.&nbsp;Using SphinxSE</h3></div></div></div><p>
To search via SphinxSE, you would need to create special ENGINE=SPHINX "search table",
and then SELECT from it with full text query put into WHERE clause for query column.
</p><p>
Let's begin with an example create statement and search query:
</p><pre class="programlisting">
CREATE TABLE t1
(
    id          INTEGER NOT NULL,
    weight      INTEGER NOT NULL,
    query       VARCHAR(3072) NOT NULL,
    group_id    INTEGER,
    INDEX(query)
) ENGINE=SPHINX CONNECTION="sphinx://localhost:3312/test";

SELECT * FROM t1 WHERE query='test it;mode=any';
</pre><p>
</p><p>
First 3 columns of search table <span class="emphasis"><em>must</em></span> be <code class="code">INTEGER</code>,
<code class="code">INTEGER</code> and <code class="code">VARCHAR</code> which will be mapped to document ID,
match weight and search query accordingly. There also must be indexes on document ID
and search query columns. These columns' names are insignficant.
</p><p>
Additional columns must be either <code class="code">INTEGER</code> or <code class="code">TIMESTAMP</code>.
They will be bound to attributes provided in Sphinx result set by name, so their
names must match attribute names specified in <code class="filename">sphinx.conf</code>.
If there's no such attribute name in Sphinx search results, column will have
<code class="code">NULL</code> values.
</p><p>
Special "virtual" attributes names can also be bound to SphinxSE columns.
<code class="code">_sph_</code> needs to be used instead of <code class="code">@</code> for that.
For instance, to obtain <code class="code">@group</code> and <code class="code">@count</code>
virtual attributes, use <code class="code">_sph_group</code> and <code class="code">_sph_count</code>
column names.
</p><p>
<code class="code">CONNECTION</code> string parameter can be used to specify default
searchd host, port and indexes for queries issued using this table.
If no connection string is specified in <code class="code">CREATE TABLE</code>,
index name "*" (ie. search all indexes) and localhost:3312 are assumed.
Connection string syntax is as follows:
</p><pre class="programlisting">
CONNECTION="sphinx://HOST:PORT/INDEXNAME"
</pre><p>
You can change the default connection string later:
</p><pre class="programlisting">
ALTER TABLE t1 CONNECTION="sphinx://NEWHOST:NEWPORT/NEWINDEXNAME";
</pre><p>
You can also override all these parameters per-query.
</p><p>
As seen in example, both query text and search options should be put
into WHERE clause on search query column (ie. 3rd column); the options
are separated by semicolons; and their names from values by equality sign.
Any number of options can be specified. Available options are:
</p><div class="itemizedlist"><ul type="disc"><li>query - query text;</li><li>mode - matching mode. Must be one of "all", "any", "phrase",
	"boolean", or "extended". Default is "all";</li><li>sort - match sorting mode. Must be one of "relevance", "attr_desc",
"attr_asc", "time_segments", or "extended". In all modes besides "relevance"
attribute name (or sorting clause for "extended") is also required after a colon:
<pre class="programlisting">
... WHERE query='test;sort=attr_asc:group_id';
... WHERE query='test;sort=extended:@weight desc, group_id asc';
</pre></li><li>offset - offset into result set, default is 0;</li><li>limit - amount of matches to retrieve from result set, default is 20;</li><li>index - names of the indexes to search:
<pre class="programlisting">
... WHERE query='test;index=test1;';
... WHERE query='test;index=test1,test2,test3;';
</pre></li><li>minid, maxid - min and max document ID to match;</li><li>weights - comma-separated list of weights to be assigned to Sphinx full-text fields:
<pre class="programlisting">
... WHERE query='test;weights=1,2,3;';
</pre></li><li>filter, !filter - comma-separated attribute name and a set of values to match:
<pre class="programlisting">
# only include groups 1, 5 and 19
... WHERE query='test;filter=group_id,1,5,19;';

# exclude groups 3 and 11
... WHERE query='test;!filter=group_id,3,11;';
</pre></li><li>range, !range - comma-separated attribute name, min and max value to match:
<pre class="programlisting">
# include groups from 3 to 7, inclusive
... WHERE query='test;range=group_id,3,7;';

# exclude groups from 5 to 25
... WHERE query='test;!range=group_id,5,25;';
</pre></li><li>maxmatches - per-query max matches value:
<pre class="programlisting">
... WHERE query='test;maxmatches=2000;';
</pre></li><li>groupby - group-by function and attribute:
<pre class="programlisting">
... WHERE query='test;groupby=day:published_ts;';
... WHERE query='test;groupby=attr:group_id;';
</pre></li><li>groupsort - group-by sorting clause:
<pre class="programlisting">
... WHERE query='test;groupsort=@count desc;';
</pre></li></ul></div><p>
</p><p>
One <span class="bold"><strong>very important</strong></span> note that it is
<span class="bold"><strong>much</strong></span> more efficient to allow Sphinx
to perform sorting, filtering and slicing the result set than to raise
max matches count and use WHERE, ORDER BY and LIMIT clauses on MySQL
side. This is for two reasons. First, Sphinx does a number of
optimizations and performs better than MySQL on these tasks.
Second, less data would need to be packed by searchd, transferred
and unpacked by SphinxSE.
</p><p>
Additional query info besides result set could be
retrieved with <code class="code">SHOW ENGINE SPHINX STATUS</code> statement:
</p><pre class="programlisting">
mysql&gt; SHOW ENGINE SPHINX STATUS;
+--------+-------+-------------------------------------------------+
| Type   | Name  | Status                                          |
+--------+-------+-------------------------------------------------+
| SPHINX | stats | total: 25, total found: 25, time: 126, words: 2 | 
| SPHINX | words | sphinx:591:1256 soft:11076:15945                | 
+--------+-------+-------------------------------------------------+
2 rows in set (0.00 sec)
</pre><p>
</p><p>
You could perform JOINs on SphinxSE search table and tables using
other engines. Here's an example with "documents" from example.sql:
</p><pre class="programlisting">
mysql&gt; SELECT content, date_added FROM test.documents docs
-&gt; JOIN t1 ON (docs.id=t1.id) 
-&gt; WHERE query="one document;mode=any";
+-------------------------------------+---------------------+
| content                             | docdate             |
+-------------------------------------+---------------------+
| this is my test document number two | 2006-06-17 14:04:28 | 
| this is my test document number one | 2006-06-17 14:04:28 | 
+-------------------------------------+---------------------+
2 rows in set (0.00 sec)

mysql&gt; SHOW ENGINE SPHINX STATUS;
+--------+-------+---------------------------------------------+
| Type   | Name  | Status                                      |
+--------+-------+---------------------------------------------+
| SPHINX | stats | total: 2, total found: 2, time: 0, words: 2 | 
| SPHINX | words | one:1:2 document:2:2                        | 
+--------+-------+---------------------------------------------+
2 rows in set (0.00 sec)
</pre><p>
</p></div></div><div class="sect1" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="reporting-bugs"></a>6.&nbsp;Reporting bugs</h2></div></div></div><p>
Unfortunately, Sphinx is not yet 100% bug free (even though I'm working hard
towards that), so you might occasionally run into some issues.
</p><p>
Reporting as much as possible about each bug is very important -
because to fix it, I need to be able either to reproduce and debug the bug,
or to deduce what's causing it from the information that you provide.
So here are some instructions on how to do that.
</p><h3><a name="id353352"></a>Build-time issues</h3><p>If Sphinx fails to build for some reason, please do the following:</p><div class="orderedlist"><ol type="1"><li>check that headers and libraries for your DBMS are properly installed
(for instance, check that <code class="filename">mysql-devel</code> package is present);
</li><li>report Sphinx version and config file (be sure to remove the passwords!),
MySQL (or PostgreSQL) configuration info, gcc version, OS version and CPU type
(ie. x86, x86-64, PowerPC, etc):
<pre class="programlisting">
mysql_config
gcc --version
uname -a
</pre></li><li>
report the error message which is produced by <code class="filename">configure</code>
or <code class="filename">gcc</code> (it should be to include error message itself only,
not the whole build log).
</li></ol></div><h3><a name="id353404"></a>Run-time issues</h3><p>
If Sphinx builds and runs, but there are any problems running it,
please do the following:
</p><div class="orderedlist"><ol type="1"><li>describe the bug (ie. both the expected behavior and actual behavior)
and all the steps necessary to reproduce it;</li><li>include Sphinx version and config file (be sure to remove the passwords!),
MySQL (or PostgreSQL) version, gcc version, OS version and CPU type (ie. x86, x86-64,
PowerPC, etc):
<pre class="programlisting">
mysql --version
gcc --version
uname -a
</pre></li><li>build, install and run debug versions of all Sphinx programs (this is
to enable a lot of additional internal checks, so-called assertions):
<pre class="programlisting">
make distclean
./configure --with-debug
make install
killall -TERM searchd
</pre></li><li>reindex to check if any assertions are triggered (in this case,
it's likely that the index is corrupted and causing problems);
</li><li>if the bug does not reproduce with debug versions,
revert to non-debug and mention it in your report;
</li><li>if the bug could be easily reproduced with a small (1-100 record)
part of your database, please provide a gzipped dump of that part;
</li><li>if the problem is related to <code class="filename">searchd</code>, include
relevant entries from <code class="filename">searchd.log</code> and
<code class="filename">query.log</code> in your bug report;
</li><li>if the problem is related to <code class="filename">searchd</code>, try
running it in console mode and check if it dies with an assertion:
<pre class="programlisting">
./searchd --console
</pre></li><li>if any program dies with an assertion, provide the assertion message.</li></ol></div><h3><a name="id353517"></a>Debugging assertions, crashes and hangups</h3><p>
If any program dies with an assertion, crashes without an assertion or hangs up,
you would additionally need to generate a core dump and examine it.
</p><div class="orderedlist"><ol type="1"><li>
enable core dumps. On most Linux systems, this is done
using <code class="filename">ulimit</code>:
<pre class="programlisting">
ulimit -c 32768
</pre></li><li>
run the program and try to reproduce the bug;
</li><li>
if the program crashes (either with or without an assertion),
find the core file in current directory (it should typically print
out "Segmentation fault (core dumped)" message);
</li><li>
if the program hangs, use <code class="filename">kill -SEGV</code>
from another console to force it to exit and dump core:
<pre class="programlisting">
kill -SEGV HANGED-PROCESS-ID
</pre></li><li>
use <code class="filename">gdb</code> to examine the core file
and obtain a backtrace:
<pre class="programlisting">
gdb ./CRASHED-PROGRAM-FILE-NAME CORE-DUMP-FILE-NAME
(gdb) bt
(gdb) quit
</pre></li></ol></div><p>
Note that HANGED-PROCESS-ID, CRASHED-PROGRAM-FILE-NAME and
CORE-DUMP-FILE-NAME must all be replaced with specific numbers
and file names. For example, hanged searchd debugging session
would look like:
</p><pre class="programlisting">
# kill -SEGV 12345
# ls *core*
core.12345
# gdb ./searchd core.12345
(gdb) bt
...
(gdb) quit
</pre><p>
</p><p>
Note that <code class="filename">ulimit</code> is not server-wide
and only affects current shell session. This means that you will not
have to restore any server-wide limits - but if you relogin,
you will have to set <code class="filename">ulimit</code> again.
</p><p>
Core dumps should be placed in current working directory
(and Sphinx programs do not change it), so this is where you
would look for them.
</p><p>
Please do not immediately remove the core file because there could
be additional helpful information which could be retrieved from it.
You do not need to send me this file (as the debug info there is
closely tied to your system) but I might need to ask
you a few additional questions about it.
</p></div><div class="sect1" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="reference"></a>7.&nbsp;<code class="filename">sphinx.conf</code> options reference</h2></div></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ref-source"></a>7.1.&nbsp;Data source configuration options</h3></div></div></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-source-type"></a>7.1.1.&nbsp;type</h4></div></div></div><p>
Data source type. Available types are <code class="option">mysql</code>, <code class="option">pgsql</code>
and <code class="option">xmlpipe</code>.
</p><p>
This option is <span class="bold"><strong>mandatory</strong></span>.
</p><h5><a name="id353700"></a>Example:</h5><pre class="programlisting">
type = mysql
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-strip-html"></a>7.1.2.&nbsp;strip_html</h4></div></div></div><p>
Whether to strip HTML formatting from incoming full-text data.
0 means that stripping should be disabled; 1 that it should be enabled.
</p><p>
Stripping currently works with <code class="option">mysql</code> and
<code class="option">pgsql</code> source, and is not yet implemented for
<code class="option">xmlpipe</code>. It should work with properly formed
HTML (such as well-formed XHTML) but MAY bug on malformed HTML
(such as with stray &lt;'s or unclosed &gt;'s).
</p><p>
This option is optional.
Default value is 0 (do not strip HTML).
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id353762"></a>Example:</h5><pre class="programlisting">
strip_html = 0
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-index-html-attrs"></a>7.1.3.&nbsp;index_html_attrs</h4></div></div></div><p>
Specifies which HTML attributes' contents still should be indexed when stripping HTML.
The format is per-tag enumeration of indexable attributes, as shown in the example below.
</p><p>
This option is optional.
Default value is empty (do not index anything).
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id353805"></a>Example:</h5><pre class="programlisting">
index_html_attrs = img=alt,title; a=title;
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-host"></a>7.1.4.&nbsp;sql_host</h4></div></div></div><p>
SQL server host to connect to.
</p><p>
This option is <span class="bold"><strong>mandatory</strong></span>.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id353849"></a>Example:</h5><pre class="programlisting">
sql_host = localhost
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-port"></a>7.1.5.&nbsp;sql_port</h4></div></div></div><p>
SQL server IP port to connect to.
</p><p>
This option is optional.
Default value is 3306 for <code class="option">mysql</code> source type and 5432 for <code class="option">pgsql</code> type.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id353895"></a>Example:</h5><pre class="programlisting">
sql_port = 3306
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-user"></a>7.1.6.&nbsp;sql_user</h4></div></div></div><p>
SQL user to use on <a href="#ref-sql-host" title="7.1.4.&nbsp;sql_host">sql_host</a>.
</p><p>
This option is <span class="bold"><strong>mandatory</strong></span>.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id353944"></a>Example:</h5><pre class="programlisting">
sql_user = test
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-pass"></a>7.1.7.&nbsp;sql_pass</h4></div></div></div><p>
SQL user password to use on <a href="#ref-sql-host" title="7.1.4.&nbsp;sql_host">sql_host</a>.
</p><p>
This option is <span class="bold"><strong>mandatory</strong></span>.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id353993"></a>Example:</h5><pre class="programlisting">
sql_pass = mysecretpassword
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-db"></a>7.1.8.&nbsp;sql_db</h4></div></div></div><p>
SQL database (in MySQL terms) to use after connection and perform further queries in.
</p><p>
This option is <span class="bold"><strong>mandatory</strong></span>.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354038"></a>Example:</h5><pre class="programlisting">
sql_db = test
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-sock"></a>7.1.9.&nbsp;sql_sock</h4></div></div></div><p>
UNIX socket name to connect to local MySQL server.
</p><p>
On Linux, it would typically be <code class="filename">/var/lib/mysql/mysql.sock</code>.
On FreeBSD, it would typically be <code class="filename">/tmp/mysql.sock</code>.
</p><p>
This option is optional.
This option only applies to <code class="option">mysql</code> source type.
</p><h5><a name="id354086"></a>Example:</h5><pre class="programlisting">
sql_sock = /tmp/mysql.sock
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-query-pre"></a>7.1.10.&nbsp;sql_query_pre</h4></div></div></div><p>
Pre-fetch query, or pre-query.
</p><p>
There might be multiple pre-queries specified. They are executed
before <a href="#ref-sql-query" title="7.1.11.&nbsp;sql_query">the main fetch query</a>
in exactly the same order they were specified in config file.
Pre-query results are ignored.
</p><p>
Pre-queries are useful to setup encoding, or mark records
which are going to be indexed, or update internal counters, etc.
</p><p>
This option is optional.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354147"></a>Example:</h5><pre class="programlisting">
sql_query_pre = SET CHARACTER_SET_RESULTS=utf-8
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-query"></a>7.1.11.&nbsp;sql_query</h4></div></div></div><p>
Main document fetch query.
</p><p>
There can be only one main query. This is the query which is used to
retrieve documents from SQL server.
</p><p>
You can specify up to 32 fields (formally, upto SPH_MAX_FIELDS from sphinx.h).
All of the fields which are not document ID or attributes will be full-text indexed.
</p><p>
Document ID <span class="bold"><strong>MUST</strong></span> be the very first field,
and it <span class="bold"><strong>MUST BE UNIQUE UNSIGNED NON-ZERO 32-BIT INTEGER NUMBER</strong></span>.
</p><p>
This option is <span class="bold"><strong>mandatory</strong></span>.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354227"></a>Example:</h5><pre class="programlisting">
sql_query = \
	SELECT id, group_id, UNIX_TIMESTAMP(date_added) AS date_added, \
		title, content \
	FROM documents
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-query-range"></a>7.1.12.&nbsp;sql_query_range</h4></div></div></div><p>
Query which fetches min/max document IDs range to be used in ranged query (see <a href="#ranged-queries">Section&nbsp;3.6, &#8220;Ranged queries&#8221;</a>).
</p><p>
This option is optional.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354271"></a>Example:</h5><pre class="programlisting">
sql_query_range = SELECT MIN(id),MAX(id) FROM documents
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-range-step"></a>7.1.13.&nbsp;sql_range_step</h4></div></div></div><p>
How much records to index per one ranged query step (see <a href="#ranged-queries">Section&nbsp;3.6, &#8220;Ranged queries&#8221;</a>).
</p><p>
This option is optional.
Default value is 1024.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354315"></a>Example:</h5><pre class="programlisting">
sql_range_step = 1000
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-group-column"></a>7.1.14.&nbsp;sql_group_column</h4></div></div></div><p>
Integer attribute column declaration. Specified column should be present among
those fetched by <a href="#ref-sql-query" title="7.1.11.&nbsp;sql_query">Section&nbsp;7.1.11, &#8220;sql_query&#8221;</a>.
</p><p>
There might be multiple attributes specified.
</p><p>
This option is optional.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354364"></a>Example:</h5><pre class="programlisting">
sql_group_column = group_id    # declare 1st attribute
sql_group_column = author_id   # declare 2nd attribute
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-date-column"></a>7.1.15.&nbsp;sql_date_column</h4></div></div></div><p>
UNIX timestamp attribute column declaration. Specified column should be present among
those fetched by <a href="#ref-sql-query" title="7.1.11.&nbsp;sql_query">Section&nbsp;7.1.11, &#8220;sql_query&#8221;</a>.
</p><p>
There might be multiple attributes specified.
</p><p>
This option is optional.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354417"></a>Example:</h5><pre class="programlisting">
sql_date_column = added_ts
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-str2ordinal-column"></a>7.1.16.&nbsp;sql_str2ordinal_column</h4></div></div></div><p>
Ordinal string number attribute column declaration. Specified column should be present among
those fetched by <a href="#ref-sql-query" title="7.1.11.&nbsp;sql_query">Section&nbsp;7.1.11, &#8220;sql_query&#8221;</a>.
</p><p>
When indexing such attributes, string values are fetched from database,
stored, sorted and then replaced by ordinal number (integer) in the sorted
strings array. These integers could then be used when searching to sort by 
by string values lexicographically.
</p><p>
<span class="bold"><strong>WARNING</strong></span>, all such string values
are going to be stored in RAM while indexing!
</p><p>
<span class="bold"><strong>WARNING</strong></span>, "C" locale will be used when sorting!
</p><p>
There might be multiple attributes specified.
</p><p>
This option is optional.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354498"></a>Example:</h5><pre class="programlisting">
sql_str2ordinal_column = author_name
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-query-post"></a>7.1.17.&nbsp;sql_query_post</h4></div></div></div><p>
Post-fetch query, executed immediately after main fetch
query (<a href="#ref-sql-query" title="7.1.11.&nbsp;sql_query">Section&nbsp;7.1.11, &#8220;sql_query&#8221;</a>) ends. If this query produces
errors, they are reported as warnings, but indexing is NOT terminated.
It's result set is ignored.
</p><p>
Note that indexing is NOT completed at the point when post-query
gets executed, and further indexing might fail.
</p><p>
This option is optional.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354553"></a>Example:</h5><pre class="programlisting">
sql_query_post = DROP TABLE my_tmp_table
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-query-post-index"></a>7.1.18.&nbsp;sql_query_post_index</h4></div></div></div><p>
Post-index query, executed when indexing is succesfully completed.
If this query produces errors, they are reported as warnings,
but indexing is NOT terminated. It's result set is ignored.
</p><p>
In this query, you can use <code class="code">$maxid</code> macro, expanded
to max document ID which was actually fetched from the database
during indexing.
</p><p>
This option is optional.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354607"></a>Example:</h5><pre class="programlisting">
sql_query_post_index = REPLACE INTO counters ( id, val ) \
    VALUES ( 'max_indexed_id', $maxid )
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-sql-query-info"></a>7.1.19.&nbsp;sql_query_info</h4></div></div></div><p>
Document info query. Only used by CLI search to fetch and display
document information; and only intended for debugging purposes.
</p><p>
This query fetches info to be displayed by CLI search utility
by document ID. Therefore, it must contain <code class="code">$id</code> macro.
</p><p>
This option is optional.
This option only applies to <code class="option">mysql</code> and <code class="option">pgsql</code> source types.
</p><h5><a name="id354662"></a>Example:</h5><pre class="programlisting">
sql_query_info = SELECT * FROM documents WHERE id=$id
</pre></div><div class="sect3" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ref-xmlpipe-command"></a>7.1.20.&nbsp;xmlpipe_command</h4></div></div></div><p>
Command which will be executed in xmlpipe mode to obtain documents.
See <a href="#xmlpipe" title="3.7.&nbsp;XMLpipe data source">Section&nbsp;3.7, &#8220;XMLpipe data source&#8221;</a> for output format description.
</p>
	# xmlpipe_command	= cat @CONFDIR@/test.xml
<p>
This option is <span class="bold"><strong>mandatory</strong></span>.
This option only applies to <code class="option">xmlpipe</code> source type.
</p><h5><a name="id354708"></a>Example:</h5><pre class="programlisting">
xmlpipe_command = cat /home/sphinx/test.xml
</pre></div></div></div><div class="appendix" lang="en"><h2 class="title" style="clear: both"><a name="changelog"></a>A.&nbsp;Sphinx revision history</h2><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ver_0_9_7"></a>A.1.&nbsp;Version 0.9.7, 02 apr 2007</h3></div></div></div><div class="itemizedlist"><ul type="disc"><li>added support for <code class="option">sql_str2ordinal_column</code></li><li>added support for upto 5 sort-by attrs (in extended sorting mode)</li><li>added support for separate groups sorting clause (in group-by mode)</li><li>added support for on-the-fly attribute updates (PRE-ALPHA; will change heavily; use for preliminary testing ONLY)</li><li>added support for zero/NULL attributes</li><li>added support for 0.9.7 features to SphinxSE</li><li>added support for n-grams (alpha, 1-grams only for now)</li><li>added support for warnings reported to client</li><li>added support for exclude-filters</li><li>added support for prefix and infix indexing (see <code class="option">max_prefix_len</code>, <code class="option">max_infix_len</code>)</li><li>added <code class="option">@*</code> syntax to reset current field to query language</li><li>added removal of duplicate entries in query index order</li><li>added PHP API workarounds for PHP signed/unsigned braindamage</li><li>added locks to avoid two concurrent indexers working on same index</li><li>added check for existing attributes vs. <code class="option">docinfo=none</code> case</li><li>improved groupby code a lot (better precision, and upto 25x times faster in extreme cases)</li><li>improved error handling and reporting</li><li>improved handling of broken indexes (reports error instead of hanging/crashing)</li><li>improved <code class="option">mmap()</code> limits for attributes and wordlists (now able to map over 4 GB on x64 and over 2 GB on x32 where possible)</li><li>improved <code class="option">malloc()</code> pressure in head daemon (search time should not degrade with time any more)</li><li>improved <code class="filename">test.php</code> command line options</li><li>improved error reporting (distributed query, broken index etc issues now reported to client)</li><li>changed default network packet size to be 8M, added extra checks</li><li>fixed division by zero in BM25 on 1-document collections (in extended matching mode)</li><li>fixed <code class="filename">.spl</code> files getting unlinked</li><li>fixed crash in schema compatibility test</li><li>fixed UTF-8 Russian stemmer</li><li>fixed requested matches count when querying distributed agents</li><li>fixed signed vs. unsigned issues everywhere (ranged queries, CLI search output, and obtaining docid)</li><li>fixed potential crashes vs. negative query offsets</li><li>fixed 0-match docs vs. extended mode vs. stats</li><li>fixed group/timestamp filters being ignored if querying from older clients</li><li>fixed docs to mention <code class="option">pgsql</code> source type</li><li>fixed issues with explicit '&amp;' in extended matching mode</li><li>fixed wrong assertion in SBCS encoder</li><li>fixed crashes with no-attribute indexes after rotate</li></ul></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ver_0_9_7_rc2"></a>A.2.&nbsp;Version 0.9.7-RC2, 15 dec 2006</h3></div></div></div><div class="itemizedlist"><ul type="disc"><li>added support for extended matching mode (query language)</li><li>added support for extended sorting mode (sorting clauses)</li><li>added support for SBCS excerpts</li><li>added <code class="option">mmap()ing</code> for attributes and wordlist (improves search time, speeds up <code class="option">fork()</code> greatly)</li><li>fixed attribute name handling to be case insensitive</li><li>fixed default compiler options to simplify post-mortem debugging (added <code class="option">-g</code>, removed <code class="option">-fomit-frame-pointer</code>)</li><li>fixed rare memory leak</li><li>fixed "hello hello" queries in "match phrase" mode</li><li>fixed issue with excerpts, texts and overlong queries</li><li>fixed logging multiple index name (no longer tokenized)</li><li>fixed trailing stopword not flushed from tokenizer</li><li>fixed boolean evaluation</li><li>fixed pidfile being wrongly <code class="option">unlink()ed</code> on <code class="option">bind()</code> failure</li><li>fixed <code class="option">--with-mysql-includes/libs</code> (they conflicted with well-known paths)</li><li>fixes for 64-bit platforms</li></ul></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ver_0_9_7_rc1"></a>A.3.&nbsp;Version 0.9.7-RC1, 26 oct 2006</h3></div></div></div><div class="itemizedlist"><ul type="disc"><li>added alpha index merging code</li><li>added an option to decrease <code class="option">max_matches</code> per-query</li><li>added an option to specify IP address for searchd to listen on</li><li>added support for unlimited amount of configured sources and indexes</li><li>added support for group-by queries</li><li>added support for /2 range modifier in charset_table</li><li>added support for arbitrary amount of document attributes</li><li>added logging filter count and index name</li><li>added <code class="option">--with-debug</code> option to configure to compile in debug mode</li><li>added <code class="option">-DNDEBUG</code> when compiling in default mode</li><li>improved search time (added doclist size hints, in-memory wordlist cache, and used VLB coding everywhere)</li><li>improved (refactored) SQL driver code (adding new drivers should be very easy now)</li><li>improved exceprts generation</li><li>fixed issue with empty sources and ranged queries</li><li>fixed querying purely remote distributed indexes</li><li>fixed suffix length check in English stemmer in some cases</li><li>fixed UTF-8 decoder for codes over U+20000 (for CJK)</li><li>fixed UTF-8 encoder for 3-byte sequences (for CJK)</li><li>fixed overshort (less than <code class="option">min_word_len</code>) words prepended to next field</li><li>fixed source connection order (indexer does not connect to all sources at once now)</li><li>fixed line numbering in config parser</li><li>fixed some issues with index rotation</li></ul></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ver_0_9_6"></a>A.4.&nbsp;Version 0.9.6, 24 jul 2006</h3></div></div></div><div class="itemizedlist"><ul type="disc"><li>added support for empty indexes</li><li>added support for multiple sql_query_pre/post/post_index</li><li>fixed timestamp ranges filter in "match any" mode</li><li>fixed configure issues with --without-mysql and --with-pgsql options</li><li>fixed building on Solaris 9</li></ul></div></div><div class="sect2" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ver_0_9_6_rc1"></a>A.5.&nbsp;Version 0.9.6-RC1, 26 jun 2006</h3></div></div></div><div class="itemizedlist"><ul type="disc"><li>added boolean queries support (experimental, beta version)</li><li>added simple file-based query cache (experimental, beta version)</li><li>added storage engine for MySQL 5.0 and 5.1 (experimental, beta version)</li><li>added GNU style <code class="filename">configure</code> script</li><li>added new searchd protocol (all binary, and should be backwards compatible)</li><li>added distributed searching support to searchd</li><li>added PostgreSQL driver</li><li>added excerpts generation</li><li>added <code class="option">min_word_len</code> option to index</li><li>added <code class="option">max_matches</code> option to searchd, removed hardcoded MAX_MATCHES limit</li><li>added initial documentation, and a working <code class="filename">example.sql</code></li><li>added support for multiple sources per index</li><li>added soundex support</li><li>added group ID ranges support</li><li>added <code class="option">--stdin</code> command-line option to search utility</li><li>added <code class="option">--noprogress</code> option to indexer</li><li>added <code class="option">--index</code> option to search</li><li>fixed UTF-8 decoder (3-byte codepoints did not work)</li><li>fixed PHP API to handle big result sets faster</li><li>fixed config parser to handle empty values properly</li><li>fixed redundant <code class="code">time(NULL)</code> calls in time-segments mode</li></ul></div></div></div></div></body></html>
